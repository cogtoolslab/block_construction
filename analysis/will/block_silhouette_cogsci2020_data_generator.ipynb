{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import urllib, io\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "\n",
    "import pymongo as pm\n",
    "from collections import Counter\n",
    "import json\n",
    "import re\n",
    "import ast\n",
    "\n",
    "from PIL import Image, ImageOps, ImageDraw, ImageFont \n",
    "\n",
    "from io import BytesIO\n",
    "import base64\n",
    "\n",
    "import  matplotlib\n",
    "from matplotlib import pylab, mlab, pyplot\n",
    "%matplotlib inline\n",
    "from IPython.core.pylabtools import figsize, getfigs\n",
    "plt = pyplot\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_context('talk')\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## directory & file hierarchy\n",
    "proj_dir = os.path.abspath('..')\n",
    "datavol_dir = os.path.join(proj_dir,'data')\n",
    "analysis_dir = os.path.abspath(os.path.join(os.getcwd(),'..'))\n",
    "results_dir = os.path.join(proj_dir,'results')\n",
    "plot_dir = os.path.join(results_dir,'plots')\n",
    "csv_dir = os.path.join(results_dir,'csv')\n",
    "json_dir = os.path.join(results_dir,'json')\n",
    "exp_dir = os.path.abspath(os.path.join(proj_dir,'experiments'))\n",
    "png_dir = os.path.abspath(os.path.join(datavol_dir,'png'))\n",
    "jefan_dir = os.path.join(analysis_dir,'jefan')\n",
    "will_dir = os.path.join(analysis_dir,'will')\n",
    "\n",
    "## add helpers to python path\n",
    "if os.path.join(proj_dir,'stimuli') not in sys.path:\n",
    "    sys.path.append(os.path.join(proj_dir,'stimuli'))\n",
    "    \n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "    \n",
    "if not os.path.exists(plot_dir):\n",
    "    os.makedirs(plot_dir)   \n",
    "    \n",
    "if not os.path.exists(csv_dir):\n",
    "    os.makedirs(csv_dir)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set vars \n",
    "auth = pd.read_csv(os.path.join(analysis_dir,'auth.txt'), header = None) # this auth.txt file contains the password for the sketchloop user\n",
    "pswd = auth.values[0][0]\n",
    "user = 'sketchloop'\n",
    "host = 'cogtoolslab.org' ## cocolab ip address\n",
    "\n",
    "# have to fix this to be able to analyze from local\n",
    "import pymongo as pm\n",
    "conn = pm.MongoClient('mongodb://sketchloop:' + pswd + '@127.0.0.1')\n",
    "db = conn['block_construction']\n",
    "coll = db['silhouette']\n",
    "\n",
    "# which iteration name should we use?\n",
    "iterationName = 'Exp2Pilot3'\n",
    "\n",
    "# variables to check integrity of data\n",
    "numTrials = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure one to one gameID and workerId \n",
    "# Should only happen if a repeat worker gets through\n",
    "\n",
    "query = coll.find({\"$and\":[\n",
    "                        {'workerId':{'$exists':True}},\n",
    "                        {'condition':{'$ne':'practice'}},\n",
    "                        {'eventType':'trial_end'},\n",
    "                        {\"$or\":[{'iterationName':'pilot2'},\n",
    "                                {'iterationName':'pilot3'},\n",
    "                                {'iterationName':'pilot4'},\n",
    "                                {'iterationName':'Exp2Pilot1'},\n",
    "                                {'iterationName':'Exp2Pilot1_turk'},\n",
    "                                {'iterationName':'Exp2Pilot1_turk'}]},\n",
    "                        {'trialNum':0}]\n",
    "                     })\n",
    "\n",
    "df_trial_end_full = pd.DataFrame(list(query.sort('timeAbsolute')))\n",
    "#df_trial_end_full[['workerId','gameID']]\n",
    "\n",
    "\n",
    "assert (np.mean(df_trial_end_full['workerId'].value_counts()) == np.mean(df_trial_end_full['gameID'].value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trial Level Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming that if trial 23 saves, then 0-22 have also saved \n",
    "# get ids of people with trial 23 data\n",
    "query = coll.find({\"$and\":[\n",
    "                        {'condition':{'$ne':'practice'}},\n",
    "                        {'eventType':'trial_end'},\n",
    "                        {'iterationName': iterationName},\n",
    "                        {'trialNum': numTrials-1}]\n",
    "                     })\n",
    "complete_data_df = pd.DataFrame(query)\n",
    "complete_data_ids = list(complete_data_df['workerId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#complete_data_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for full datasets\n",
    "query = coll.find({\"$and\":[\n",
    "                        {'condition':{'$ne':'practice'}},\n",
    "                        {'eventType':'trial_end'},\n",
    "                        {'iterationName':iterationName}]\n",
    "                     })\n",
    "\n",
    "df_trial_end_full = pd.DataFrame(list(query.sort('timeAbsolute')))\n",
    "\n",
    "\n",
    "# filter dataframe for complete datasets\n",
    "df_trial_end_full_filtered = df_trial_end_full[df_trial_end_full.workerId.isin(complete_data_ids)]\n",
    "\n",
    "# reduce to crucial information\n",
    "df_trial_end_reduced_filtered = df_trial_end_full_filtered[[\n",
    "    'gameID','trialNum','phase','condition','eventType','targetName','repetition','targetID', #trial identifiers\n",
    "    'nullScore','F1Score','normedScore','rawScoreDiscrete','nullScoreDiscrete','normedScoreDiscrete','scoreGapDiscrete', #scoring\n",
    "    'numBlocks','nPracticeAttempts','blockColor','blockColorID','blockFell','doNothingRepeats',#misc. trial info\n",
    "    'score','currBonus','timeBonus', #bonusing\n",
    "    'timeAbsolute','timeRelative','buildTime','buildStartTime','buildFinishTime','timeToBuild', #timing \n",
    "    'discreteWorld','allVertices', #world reconstruction\n",
    "    'browser','browserVersion','os','devMode', #developer info\n",
    "    #below here should be the same for every trial in a dataset\n",
    "    'iterationName',\n",
    "    'numTargets', 'prePostSetSize','numRepetitions', #pre-post info\n",
    "    'bonusThresholdLow','bonusThresholdMid','bonusThresholdHigh','timeThresholdYellow','timeThresholdRed', #bonus info\n",
    "    ]]\n",
    "\n",
    "#Fix error in data-saving- normedScoreDiscrete saved as rawScoreDiscrete\n",
    "df_trial_end_reduced_filtered['normedScoreDiscrete'] = df_trial_end_reduced_filtered['rawScoreDiscrete']\n",
    "df_trial_end_reduced_filtered.drop(['rawScoreDiscrete'], axis=1)\n",
    "\n",
    "\n",
    "df = df_trial_end_reduced_filtered.sort_values(by=['gameID', 'timeAbsolute'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Spatial Reconstruction Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetMaps = {}\n",
    "\n",
    "with open(os.path.join(csv_dir,'targetMaps.txt')) as json_file:\n",
    "    targetMaps = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPrecision(arr1,arr2):\n",
    "    prod = np.multiply(arr1,arr2)\n",
    "    false_pos = np.subtract(arr2,prod)\n",
    "    numerator = np.sum(prod)\n",
    "    denominator = np.add(numerator,np.sum(false_pos))\n",
    "    recall = numerator/denominator\n",
    "    return recall\n",
    "\n",
    "def getRecall(arr1,arr2):\n",
    "    prod = np.multiply(arr1,arr2)\n",
    "    false_neg = np.subtract(arr1,prod)\n",
    "    numerator = np.sum(prod)\n",
    "    denominator = np.add(np.sum(prod),np.sum(false_neg))\n",
    "    recall = numerator/denominator\n",
    "    return recall\n",
    "\n",
    "def getF1Score(targetName, discreteWorld):\n",
    "    targetMap = targetMaps[targetName]\n",
    "    arr1 = 1*np.logical_not(np.array(targetMap))\n",
    "    arr2 = 1*np.logical_not(np.array(discreteWorld))\n",
    "    recall = getRecall(arr1, arr2)\n",
    "    precision = getPrecision(arr1, arr2)\n",
    "    numerator = np.multiply(precision, recall)\n",
    "    denominator = np.add(precision, recall)\n",
    "    quotient = np.divide(numerator, denominator)\n",
    "    f1Score = np.multiply(2, quotient)\n",
    "    #print('recall ' + recall);\n",
    "    return f1Score\n",
    "\n",
    "def getF1ScoreLambda(row):\n",
    "    return(getF1Score(row['targetName'], row['discreteWorld']))\n",
    "\n",
    "\n",
    "def getJaccard(targetName, discreteWorld):\n",
    "    targetMap = targetMaps[targetName]\n",
    "    arr1 = 1*np.logical_not(np.array(targetMap))\n",
    "    arr2 = 1*np.logical_not(np.array(discreteWorld))\n",
    "    \n",
    "    prod = np.multiply(arr1,arr2)\n",
    "    true_pos = np.sum(prod)\n",
    "    false_pos = np.sum(np.subtract(arr2,prod))\n",
    "    false_neg = np.sum(np.subtract(arr1,prod))\n",
    "#     print(true_pos)\n",
    "#     print(false_pos)\n",
    "#     print(false_neg)\n",
    "\n",
    "    denomenator = np.add(false_neg,np.add(false_pos,true_pos))\n",
    "    jaccard = np.divide(true_pos,denomenator)\n",
    "    #print('recall ' + recall);\n",
    "    return jaccard\n",
    "\n",
    "def getJaccardLambda(row):\n",
    "    return(getJaccard(row['targetName'], row['discreteWorld']))\n",
    "\n",
    "# def getNullScore(targetName):\n",
    "#     targetMap = targetMaps[targetName]\n",
    "#     arr1 = 1*np.logical_not(np.array(targetMap))\n",
    "#     arr2 = 1*np.zeros(arr1.shape)\n",
    "#     recall = getRecall(arr1, arr2)\n",
    "#     precision = getPrecision(arr1, arr2)\n",
    "#     numerator = np.multiply(precision, recall)\n",
    "#     denominator = np.add(precision, recall)\n",
    "#     quotient = np.divide(numerator, denominator)\n",
    "#     f1Score = np.multiply(2, quotient)\n",
    "#     print('recall ', str(recall));\n",
    "#     print('precision ', str(precision));\n",
    "#     print('quotient ', str(quotient));\n",
    "#     return f1Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rawF1DiscreteScore'] =  df.apply(getF1ScoreLambda, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['jaccardDiscrete'] = df.apply(getJaccardLambda, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make new column: phase_extended\n",
    "# Same as phase but with 'repeated' split into 'repetition 1' and 'repetition 2'\n",
    "\n",
    "phase_dict = {\n",
    "    'pre':0,\n",
    "    'repetition 1':1,\n",
    "    'repetition 2':2,\n",
    "    'post':3\n",
    "}\n",
    "\n",
    "ordered_phases = ['pre','repetition 1','repetition 2','post']\n",
    "\n",
    "\n",
    "df['phase_extended'] = df['phase']\n",
    "df.loc[(df.phase=='repeated') & (df.repetition==1),'phase_extended'] = 'repetition 1'\n",
    "df.loc[(df.phase=='repeated') & (df.repetition==2),'phase_extended'] = 'repetition 2'\n",
    "\n",
    "\n",
    "df['phase_number'] = df.phase_extended.astype(\"category\",\n",
    "                                              ordered=True,\n",
    "                                              categories=ordered_phases).cat.codes\n",
    "\n",
    "dfi['phase_extended'] = dfi['phase']\n",
    "dfi.loc[(df.phase=='repeated') & (dfi.repetition==1),'phase_extended'] = 'repetition 1'\n",
    "dfi.loc[(df.phase=='repeated') & (dfi.repetition==2),'phase_extended'] = 'repetition 2'\n",
    "\n",
    "\n",
    "dfi['phase_number'] = dfi.phase_extended.astype(\"category\",\n",
    "                                              ordered=True,\n",
    "                                              categories=ordered_phases).cat.codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add useful variables for graphing\n",
    "\n",
    "df['targetNumber'] = df['targetName'].apply(lambda x: x[-2:])\n",
    "df['perfectScore'] = df.rawF1DiscreteScore == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Block Data\n",
    "Initial block placements (before physics, after snapping, before falling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = coll.find({\"$and\":[\n",
    "                        {'condition':{'$ne':'practice'}},\n",
    "                        {'eventType':'initial'},\n",
    "                        {'iterationName':iterationName}]\n",
    "                     })\n",
    "\n",
    "df_initial_full = pd.DataFrame(list(query))\n",
    "\n",
    "# filter dataframe for complete datasets\n",
    "df_initial_full_filtered = df_initial_full[df_initial_full.workerId.isin(complete_data_ids)]\n",
    "\n",
    "print('Loaded ' + str(df_initial_full_filtered.shape[0]) + ' complete sets of initial blocks')\n",
    "# reduce to crucial information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_initial_full_filtered.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_initial_reduced_filtered = df_initial_full_filtered[[\n",
    "    'gameID','trialNum','phase','condition','eventType','targetName','repetition','targetID','blockNum', #trial identifiers\n",
    "    'nullScore','incrementalScore','normedIncrementalScore','rawScoreDiscrete','incrementalNormedScoreDiscretePrevious', #scoring\n",
    "    'score','currBonus', #bonusing\n",
    "    'timeAbsolute','timeRelative','timeBlockSelected','timeBlockPlaced','relativePlacementTime', #timing \n",
    "    'discreteWorld','vertices','blockKind','blockColorID','blockColor','blockCenterX', 'blockCenterY', #world reconstruction\n",
    "    'x_index','y_index','x_discrete','y_discrete','width_discrete','height_discrete'\n",
    "    ]]\n",
    "\n",
    "df_initial_reduced_filtered = df_initial_reduced_filtered.sort_values(by=['gameID', 'timeAbsolute'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfi = df_initial_reduced_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settled Block Data\n",
    "Block data after coming to rest (after physics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = coll.find({\"$and\":[\n",
    "                        {'condition':{'$ne':'practice'}},\n",
    "                        {'eventType':'settled'},\n",
    "                        {'iterationName':iterationName}]\n",
    "                     })\n",
    "\n",
    "df_settled_full = pd.DataFrame(list(query))\n",
    "\n",
    "\n",
    "# filter dataframe for complete datasets\n",
    "df_settled_full_filtered = df_settled_full[df_settled_full.workerId.isin(complete_data_ids)]\n",
    "\n",
    "print('Loaded ' + str(df_settled_full_filtered.shape[0]) + ' complete sets of settled blocks')\n",
    "# reduce to crucial information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_settled_full_filtered.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_settled_reduced_filtered = df_settled_full_filtered[[\n",
    "    'gameID','trialNum','phase','condition','eventType','targetName','repetition','targetID', #trial identifiers\n",
    "    'nullScore','incrementalScore','normedIncrementalScore','rawScoreDiscrete','incrementalNormedScoreDiscrete','numBlocks','blockFell', #scoring\n",
    "    'score','currBonus', #bonusing\n",
    "    'timeAbsolute','timeRelative',#timing \n",
    "    'discreteWorld','allVertices','blockKind','blockColorID','blockColor','blockCenterX', 'blockCenterY',#world reconstruction\n",
    "    'x_index','y_index','x_discrete','y_discrete'\n",
    "    ]]\n",
    "\n",
    "df_settled_reduced_filtered = df_settled_reduced_filtered.sort_values(by=['gameID', 'timeAbsolute'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = df_settled_reduced_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Survey Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = coll.find({\"$and\":[\n",
    "                        {'eventType':'survey_data'},\n",
    "                        {'iterationName':iterationName}]\n",
    "                     })\n",
    "df_survey = pd.DataFrame(list(query.sort('absoluteTime')))\n",
    "df_survey[['gameID','age','comments','difficulty','fun','strategies','inputDevice','sex','score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning (bugs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove two block placements (potentially from refreshing?)\n",
    "# These were recorded but don't seem to be a part of the final structure\n",
    "# Believe they are from refreshing\n",
    "\n",
    "dfi = dfi[~(((dfi.gameID == '4611-415301bd-3cd2-4751-9911-e530d1bce758') & \n",
    "        (dfi.trialNum==1) & \n",
    "        (dfi.blockNum == 1) & \n",
    "        (dfi.blockKind=='D')) |\n",
    "    ((dfi.gameID == '2328-cf96d18d-a95b-4d1b-bc43-602ee1bf5835') & \n",
    "        (dfi.trialNum==0) & \n",
    "        (dfi.blockNum == 1) & \n",
    "        (dfi.blockKind=='E')))]\n",
    "\n",
    "dfs = dfs[~(((dfi.gameID == '4611-415301bd-3cd2-4751-9911-e530d1bce758') & \n",
    "        (dfs.trialNum==1) & \n",
    "        (dfs.numBlocks == 1) & \n",
    "        (dfs.blockKind=='D')) |\n",
    "    ((dfs.gameID == '2328-cf96d18d-a95b-4d1b-bc43-602ee1bf5835') & \n",
    "        (dfs.trialNum==0) & \n",
    "        (dfs.numBlocks == 1) & \n",
    "        (dfs.blockKind=='E')))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mark a participant as buggy\n",
    "\n",
    "df['buggy'] = False\n",
    "dfs['buggy'] = False\n",
    "dfi['buggy'] = False\n",
    "df_survey['buggy'] = False\n",
    "\n",
    "#Mark this participant as bugs found leading to >60s build time. Perhaps a very slow computer?\n",
    "df.loc[df.gameID==\"3988-e15c8e2e-0b53-43fd-a2d3-686d3efd6923\",'buggy'] = True \n",
    "dfs.loc[dfs.gameID==\"3988-e15c8e2e-0b53-43fd-a2d3-686d3efd6923\",'buggy'] = True \n",
    "dfi.loc[dfi.gameID==\"3988-e15c8e2e-0b53-43fd-a2d3-686d3efd6923\",'buggy'] = True\n",
    "df_survey.loc[df_survey.gameID==\"3988-e15c8e2e-0b53-43fd-a2d3-686d3efd6923\",'buggy'] = True\n",
    "\n",
    "#Mark this participant as NaNs found for two scores.\n",
    "df.loc[df.gameID==\"4739-25f27c31-0d4c-46ae-a515-02351c69042d\",'buggy'] = True \n",
    "dfs.loc[dfs.gameID==\"4739-25f27c31-0d4c-46ae-a515-02351c69042d\",'buggy'] = True \n",
    "dfi.loc[dfi.gameID==\"4739-25f27c31-0d4c-46ae-a515-02351c69042d\",'buggy'] = True \n",
    "df_survey.loc[df_survey.gameID==\"4739-25f27c31-0d4c-46ae-a515-02351c69042d\",'buggy'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## re-code last repetition for control towers as 3 instead of 1\n",
    "df.loc[(df['condition']=='control') & (df['repetition']==1),'repetition'] = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inter-block-interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMeanIBI(values):\n",
    "    '''Obtain mean time between block placements'''\n",
    "    ibis = [] \n",
    "    for x, y in zip(values[0::], values[1::]): \n",
    "        #print(x,y)\n",
    "        ibi = y-x\n",
    "        assert(ibi >= 0)\n",
    "        ibis.append(y-x)\n",
    "    return np.mean(ibis)\n",
    "\n",
    "def getMedianIBI(values):\n",
    "    '''Obtain mean time between block placements'''\n",
    "    ibis = [] \n",
    "    for x, y in zip(values[0::], values[1::]): \n",
    "        #print(x,y)\n",
    "        ibi = y-x\n",
    "        assert(ibi >= 0)\n",
    "        ibis.append(y-x)\n",
    "    return np.median(ibis)\n",
    "\n",
    "\n",
    "def getSDIBI(values):\n",
    "    '''Obtain mean time between block placements'''\n",
    "    ibis = [] \n",
    "    for x, y in zip(values[0::], values[1::]): \n",
    "        #print(x,y)\n",
    "        ibi = y-x\n",
    "        assert(ibi >= 0)\n",
    "        ibis.append(y-x)\n",
    "    return np.std(ibis)\n",
    "\n",
    "def getMinIBI(values):\n",
    "    '''Obtain mean time between block placements'''\n",
    "    ibis = [] \n",
    "    for x, y in zip(values[0::], values[1::]): \n",
    "        #print(x,y)\n",
    "        ibi = y-x\n",
    "        assert(ibi >= 0)\n",
    "        ibis.append(y-x)\n",
    "    return np.min(ibis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfi = dfi.drop_duplicates(subset=['gameID','trialNum','blockNum'], keep='last')\n",
    "\n",
    "dfIBIMean = dfi.sort_values('timeAbsolute').groupby(['gameID','trialNum'])['relativePlacementTime']\\\n",
    "                    .agg(getMeanIBI).reset_index()\n",
    "dfIBIMean = dfIBIMean.rename(columns = {'relativePlacementTime':'meanIBI'})\n",
    "df = pd.merge(df, dfIBIMean, how='left', on=['gameID','trialNum'])\n",
    "\n",
    "dfIBIMin = dfi.sort_values('timeAbsolute').groupby(['gameID','trialNum'])['relativePlacementTime']\\\n",
    "                    .agg(getMinIBI).reset_index()\n",
    "dfIBIMin = dfIBIMin.rename(columns = {'relativePlacementTime':'minIBI'})\n",
    "df = pd.merge(df, dfIBIMin, how='left', on=['gameID','trialNum'])\n",
    "\n",
    "thinking_time = dfi[dfi.blockNum==1][['gameID','trialNum','relativePlacementTime']]\n",
    "thinking_time = thinking_time.rename(columns = {'relativePlacementTime':'thinkingTime'})\n",
    "df = pd.merge(df, thinking_time, how='left', on=['gameID','trialNum'])\n",
    "\n",
    "dfIBIMedian = dfi.sort_values('timeAbsolute').groupby(['gameID','trialNum'])['relativePlacementTime']\\\n",
    "                    .agg(getMedianIBI).reset_index()\n",
    "dfIBIMedian = dfIBIMedian.rename(columns = {'relativePlacementTime':'medianIBI'})\n",
    "df = pd.merge(df, dfIBIMedian, how='left', on=['gameID','trialNum'])\n",
    "\n",
    "dfIBISD = dfi.sort_values('timeAbsolute').groupby(['gameID','trialNum'])['relativePlacementTime']\\\n",
    "                    .agg(getSDIBI).reset_index()\n",
    "dfIBISD = dfIBISD.rename(columns = {'relativePlacementTime':'sdIBI'})\n",
    "df = pd.merge(df, dfIBISD, how='left', on=['gameID','trialNum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trial_end_full_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = os.path.join(csv_dir,'block_silhouette_{}.csv'.format(iterationName))\n",
    "df.to_csv(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = os.path.join(csv_dir,'block_silhouette_initial_{}.csv'.format(iterationName))\n",
    "dfi.to_csv(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = os.path.join(csv_dir,'block_silhouette_settled_{}.csv'.format(iterationName))\n",
    "dfs.to_csv(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = os.path.join(csv_dir,'block_silhouette_{}_good.csv'.format(iterationName))\n",
    "df[~df.buggy].to_csv(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = os.path.join(csv_dir,'block_silhouette_initial_{}_good.csv'.format(iterationName))\n",
    "dfi[~dfi.buggy].to_csv(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = os.path.join(csv_dir,'block_silhouette_settled_{}_good.csv'.format(iterationName))\n",
    "dfs[~dfs.buggy].to_csv(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = os.path.join(csv_dir,'block_silhouette_survey_{}.csv'.format(iterationName))\n",
    "df_survey.to_csv(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_survey[~df_survey.buggy][['gameID','age','comments','difficulty','fun','strategies','inputDevice','sex','score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('age mean: ', df_survey[~df_survey.buggy]['age'].apply(int).mean())\n",
    "print('age std: ', df_survey[~df_survey.buggy]['age'].apply(int).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_survey[~df_survey.buggy]['sex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('bonus mean: ', df_survey[~df_survey.buggy]['score'].mean())\n",
    "print('bonus std: ', df_survey[~df_survey.buggy]['score'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
