{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import urllib, io\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "\n",
    "import pymongo as pm\n",
    "from collections import Counter\n",
    "import json\n",
    "import re\n",
    "import ast\n",
    "\n",
    "from PIL import Image, ImageOps, ImageDraw, ImageFont \n",
    "\n",
    "from io import BytesIO\n",
    "import base64\n",
    "\n",
    "import  matplotlib\n",
    "from matplotlib import pylab, mlab, pyplot\n",
    "%matplotlib inline\n",
    "from IPython.core.pylabtools import figsize, getfigs\n",
    "plt = pyplot\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_context('talk')\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## directory & file hierarchy\n",
    "proj_dir = os.path.abspath('..')\n",
    "datavol_dir = os.path.join(proj_dir,'data')\n",
    "analysis_dir = os.path.abspath(os.path.join(os.getcwd(),'..'))\n",
    "results_dir = os.path.join(proj_dir,'results')\n",
    "plot_dir = os.path.join(results_dir,'plots')\n",
    "csv_dir = os.path.join(results_dir,'csv')\n",
    "json_dir = os.path.join(results_dir,'json')\n",
    "exp_dir = os.path.abspath(os.path.join(proj_dir,'experiments'))\n",
    "png_dir = os.path.abspath(os.path.join(datavol_dir,'png'))\n",
    "jefan_dir = os.path.join(analysis_dir,'jefan')\n",
    "will_dir = os.path.join(analysis_dir,'will')\n",
    "\n",
    "## add helpers to python path\n",
    "if os.path.join(proj_dir,'stimuli') not in sys.path:\n",
    "    sys.path.append(os.path.join(proj_dir,'stimuli'))\n",
    "    \n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "    \n",
    "if not os.path.exists(plot_dir):\n",
    "    os.makedirs(plot_dir)   \n",
    "    \n",
    "if not os.path.exists(csv_dir):\n",
    "    os.makedirs(csv_dir)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set vars \n",
    "auth = pd.read_csv(os.path.join(analysis_dir,'auth.txt'), header = None) # this auth.txt file contains the password for the sketchloop user\n",
    "pswd = auth.values[0][0]\n",
    "user = 'sketchloop'\n",
    "host = 'cogtoolslab.org' ## cocolab ip address\n",
    "\n",
    "# have to fix this to be able to analyze from local\n",
    "import pymongo as pm\n",
    "conn = pm.MongoClient('mongodb://sketchloop:' + pswd + '@127.0.0.1')\n",
    "db = conn['block_construction']\n",
    "coll = db['silhouette']\n",
    "\n",
    "# which iteration name should we use?\n",
    "iterationName = 'Exp2Pilot3'\n",
    "\n",
    "# variables to check integrity of data\n",
    "numTrials = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure one to one gameID and workerId \n",
    "# Should only happen if a repeat worker gets through\n",
    "\n",
    "query = coll.find({\"$and\":[\n",
    "                        {'workerId':{'$exists':True}},\n",
    "                        {'condition':{'$ne':'practice'}},\n",
    "                        {'eventType':'trial_end'},\n",
    "                        {\"$or\":[{'iterationName':'pilot2'},\n",
    "                                {'iterationName':'pilot3'},\n",
    "                                {'iterationName':'pilot4'},\n",
    "                                {'iterationName':'Exp2Pilot1'},\n",
    "                                {'iterationName':'Exp2Pilot1_turk'},\n",
    "                                {'iterationName':'Exp2Pilot1_turk'}]},\n",
    "                        {'trialNum':0}]\n",
    "                     })\n",
    "\n",
    "df_trial_end_full = pd.DataFrame(list(query.sort('timeAbsolute')))\n",
    "#df_trial_end_full[['workerId','gameID']]\n",
    "\n",
    "\n",
    "assert (np.mean(df_trial_end_full['workerId'].value_counts()) == np.mean(df_trial_end_full['gameID'].value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find full datasets for Silhouette_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming that if trial 23 saves, then 0-22 have also saved \n",
    "# get ids of people with trial 23 data\n",
    "query = coll.find({\"$and\":[\n",
    "                        {'condition':{'$ne':'practice'}},\n",
    "                        {'eventType':'trial_end'},\n",
    "                        {'iterationName': iterationName},\n",
    "                        {'trialNum': numTrials-1}]\n",
    "                     })\n",
    "complete_data_df = pd.DataFrame(query)\n",
    "complete_data_ids = list(complete_data_df['workerId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A2ZDEERVRN5AMC',\n",
       " 'A17FGZ1I5P9RZA',\n",
       " 'A2LANO898EAYKJ',\n",
       " 'ALLP45O3BDWYM',\n",
       " 'A1LA6CIGBNDOH9',\n",
       " 'AY832D29HUURG',\n",
       " 'A28UGNCW3YMSTH',\n",
       " 'A1ROEDVMTO9Y3X',\n",
       " 'ARL7HOWLEHNOP',\n",
       " 'AMV1E7FFPVAW4',\n",
       " 'A1VR1XQEQQXYUE',\n",
       " 'A3CWYWKQXX4RIZ',\n",
       " 'A3FT3XPTOWHJMY',\n",
       " 'A1CY7IOJ9YH136',\n",
       " 'A1X84T4EFW04GZ',\n",
       " 'A3G16WWK0QUQ80',\n",
       " 'A314ERJIHRSDY7',\n",
       " 'A2HHWFGVV9UUC5',\n",
       " 'A3LXD82BMSRT2F',\n",
       " 'A7O82NXM2PI12',\n",
       " 'ANGJ99ZU0TTGO',\n",
       " 'A2EA2PN47ZWILX',\n",
       " 'A5NHP0N1XC09K',\n",
       " 'A1F669OTXWIJW0',\n",
       " 'AT468RB7BWBQW',\n",
       " 'A3V57BKH58EUIY',\n",
       " 'AEF74ZYJTTEIA',\n",
       " 'AVT79B8F5O9LI',\n",
       " 'A1YFVXP4A1CXSF',\n",
       " 'A2GLSQQQE9UZA6',\n",
       " 'A2LAMCJLVCRQ4T',\n",
       " 'A1M682B2WUSYJP',\n",
       " 'A2GA29WTMFW2W',\n",
       " 'A1TMZLYXQAK8Q0',\n",
       " 'A2196WCNDZULFS',\n",
       " 'A2MCG5W6LHSRG9',\n",
       " 'A1OVGCI9KUL4MI',\n",
       " 'A2LF84L3K71GR2',\n",
       " 'AQOXSP4W3ITSW',\n",
       " 'AG9LWKO86TNHG',\n",
       " 'A2UCTX06NM6Y02',\n",
       " 'AFIK3VBMMX6G6',\n",
       " 'A3LI18V0QQ34YK',\n",
       " 'AILDNTO2TWB4A',\n",
       " 'A3K0E7TSPX25GH',\n",
       " 'AEQ8K4HBO323D',\n",
       " 'A3MLUEOP3CCLXL',\n",
       " 'A39MKVROUZ1UWR',\n",
       " 'A2QTSQ26FID1FK',\n",
       " 'A1H3IOEYN0VNB2',\n",
       " 'A3QEVFM3UD67BA']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_data_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/will/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# Filter for full datasets\n",
    "query = coll.find({\"$and\":[\n",
    "                        {'condition':{'$ne':'practice'}},\n",
    "                        {'eventType':'trial_end'},\n",
    "                        {'iterationName':iterationName}]\n",
    "                     })\n",
    "\n",
    "df_trial_end_full = pd.DataFrame(list(query.sort('timeAbsolute')))\n",
    "\n",
    "\n",
    "# filter dataframe for complete datasets\n",
    "df_trial_end_full_filtered = df_trial_end_full[df_trial_end_full.workerId.isin(complete_data_ids)]\n",
    "\n",
    "# reduce to crucial information\n",
    "df_trial_end_reduced_filtered = df_trial_end_full_filtered[[\n",
    "    'gameID','trialNum','phase','condition','eventType','targetName','repetition','targetID', #trial identifiers\n",
    "    'nullScore','F1Score','normedScore','rawScoreDiscrete','nullScoreDiscrete','normedScoreDiscrete','scoreGapDiscrete', #scoring\n",
    "    'numBlocks','nPracticeAttempts','blockColor','blockColorID','blockFell','doNothingRepeats',#misc. trial info\n",
    "    'score','currBonus','timeBonus', #bonusing\n",
    "    'timeAbsolute','timeRelative','buildTime','buildStartTime','buildFinishTime','timeToBuild', #timing \n",
    "    'discreteWorld','allVertices', #world reconstruction\n",
    "    'browser','browserVersion','os','devMode', #developer info\n",
    "    #below here should be the same for every trial in a dataset\n",
    "    'iterationName',\n",
    "    'numTargets', 'prePostSetSize','numRepetitions', #pre-post info\n",
    "    'bonusThresholdLow','bonusThresholdMid','bonusThresholdHigh','timeThresholdYellow','timeThresholdRed', #bonus info\n",
    "    ]]\n",
    "\n",
    "#Fix error in data-saving- normedScoreDiscrete saved as rawScoreDiscrete\n",
    "df_trial_end_reduced_filtered['normedScoreDiscrete'] = df_trial_end_reduced_filtered['rawScoreDiscrete']\n",
    "df_trial_end_reduced_filtered.drop(['rawScoreDiscrete'], axis=1)\n",
    "\n",
    "\n",
    "df = df_trial_end_reduced_filtered.sort_values(by=['gameID', 'timeAbsolute'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetMaps = {}\n",
    "\n",
    "with open(os.path.join(csv_dir,'targetMaps.txt')) as json_file:\n",
    "    targetMaps = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPrecision(arr1,arr2):\n",
    "    print(arr1)\n",
    "    print(arr2)\n",
    "    prod = np.multiply(arr1,arr2)\n",
    "    false_pos = np.subtract(arr2,prod)\n",
    "    numerator = np.sum(prod)\n",
    "    denominator = np.add(numerator,np.sum(false_pos))\n",
    "    recall = numerator/denominator\n",
    "    return recall\n",
    "\n",
    "def getRecall(arr1,arr2):\n",
    "    prod = np.multiply(arr1,arr2)\n",
    "    false_neg = np.subtract(arr1,arr2)\n",
    "    numerator = np.sum(prod)\n",
    "    denominator = np.add(np.sum(prod),np.sum(false_neg))\n",
    "    recall = numerator/denominator\n",
    "    return recall\n",
    "\n",
    "def getF1Score(targetName, discreteWorld):\n",
    "    targetMap = targetMaps[targetName]\n",
    "    arr1 = 1*np.logical_not(np.array(targetMap))\n",
    "    arr2 = 1*np.logical_not(np.array(discreteWorld))\n",
    "    recall = getRecall(arr1, arr2)\n",
    "    precision = getPrecision(arr1, arr2)\n",
    "    numerator = np.multiply(precision, recall)\n",
    "    denominator = np.add(precision, recall)\n",
    "    quotient = np.divide(numerator, denominator)\n",
    "    f1Score = np.multiply(2, quotient)\n",
    "    #print('recall ' + recall);\n",
    "    return f1Score\n",
    "\n",
    "def getF1ScoreLambda(row):\n",
    "    return(getF1Score(row['targetName'], row['discreteWorld']))\n",
    "    \n",
    "def getNullScore(targetName):\n",
    "    targetMap = targetMaps[targetName]\n",
    "    arr1 = 1*np.logical_not(np.array(targetMap))\n",
    "    arr2 = 1*np.zeros(arr1.shape)\n",
    "    recall = getRecall(arr1, arr2)\n",
    "    precision = getPrecision(arr1, arr2)\n",
    "    numerator = np.multiply(precision, recall)\n",
    "    denominator = np.add(precision, recall)\n",
    "    quotient = np.divide(numerator, denominator)\n",
    "    f1Score = np.multiply(2, quotient)\n",
    "    print('recall ', str(recall));\n",
    "    print('precision ', str(precision));\n",
    "    print('quotient ', str(quotient));\n",
    "    return f1Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 0 0 0 0 0 0]\n",
      " [1 1 0 0 1 1 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 1 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 1 0 0 0 0 0]\n",
      " [1 1 0 0 1 1 1 1 0 0 0 0 0]\n",
      " [1 1 1 1 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "recall  0.0\n",
      "precision  nan\n",
      "quotient  nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/will/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getNullScore('hand_selected_009')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9010989010989011"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getF1Score(df.targetName[0],df.discreteWorld[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/will/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  app.launch_new_instance()\n",
      "/Users/will/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:27: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "742     0.883721\n",
       "754     0.500000\n",
       "766     0.717949\n",
       "778     0.731707\n",
       "792     0.551724\n",
       "803     0.869565\n",
       "815     0.370370\n",
       "826     0.776471\n",
       "839     0.818182\n",
       "853     0.800000\n",
       "866     0.375000\n",
       "881     0.886076\n",
       "895     0.588235\n",
       "909     0.613333\n",
       "923     0.826667\n",
       "933     0.555556\n",
       "946     0.611111\n",
       "959     0.727273\n",
       "970     0.776471\n",
       "985     0.857143\n",
       "992     0.794521\n",
       "1000    0.631579\n",
       "1007    0.736842\n",
       "1013    0.631579\n",
       "710     0.400000\n",
       "715     1.000000\n",
       "721     1.000000\n",
       "729     0.896552\n",
       "739     0.949495\n",
       "752     0.864865\n",
       "          ...   \n",
       "654     1.000000\n",
       "658     1.000000\n",
       "663     1.000000\n",
       "669     1.000000\n",
       "672     1.000000\n",
       "676     1.000000\n",
       "150     0.492754\n",
       "158     0.717949\n",
       "167     0.731707\n",
       "175     0.686567\n",
       "185     0.864865\n",
       "193     1.000000\n",
       "201     0.916667\n",
       "208     0.857143\n",
       "215     0.594595\n",
       "221     0.833333\n",
       "230     1.000000\n",
       "238     0.760563\n",
       "246     0.950000\n",
       "259     0.980392\n",
       "266     0.844444\n",
       "274     0.724638\n",
       "281     0.322581\n",
       "288     0.594595\n",
       "296     0.989474\n",
       "301     0.780488\n",
       "307     0.871795\n",
       "312     0.857143\n",
       "317     0.687500\n",
       "321     0.938776\n",
       "Length: 1224, dtype: float64"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rawF1DiscreteScore'] =  df.apply(getF1ScoreLambda, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(df['rawF1DiscreteScore']0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/will/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3325: FutureWarning: specifying 'categories' or 'ordered' in .astype() is deprecated; pass a CategoricalDtype instead\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "# Make new column: phase_extended\n",
    "# Same as phase but with 'repeated' split into 'repetition 1' and 'repetition 2'\n",
    "\n",
    "df['phase_extended'] = df['phase']\n",
    "df.loc[(df.phase=='repeated') & (df.repetition==1),'phase_extended'] = 'repetition 1'\n",
    "df.loc[(df.phase=='repeated') & (df.repetition==2),'phase_extended'] = 'repetition 2'\n",
    "\n",
    "phase_dict = {\n",
    "    'pre':0,\n",
    "    'repetition 1':1,\n",
    "    'repetition 2':2,\n",
    "    'post':3\n",
    "}\n",
    "\n",
    "ordered_phases = ['pre','repetition 1','repetition 2','post']\n",
    "df['phase_number'] = df.phase_extended.astype(\"category\",\n",
    "                                              ordered=True,\n",
    "                                              categories=ordered_phases).cat.codes\n",
    "\n",
    "#df['phase_number'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = os.path.join(csv_dir,'block_silhouette_{}.csv'.format(iterationName))\n",
    "df.to_csv(out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Block Data\n",
    "Initial block placements (before physics, after snapping, before falling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = coll.find({\"$and\":[\n",
    "                        {'condition':{'$ne':'practice'}},\n",
    "                        {'eventType':'initial'},\n",
    "                        {'iterationName':iterationName}]\n",
    "                     })\n",
    "\n",
    "df_initial_full = pd.DataFrame(list(query))\n",
    "\n",
    "# filter dataframe for complete datasets\n",
    "df_initial_full_filtered = df_initial_full[df_initial_full.workerId.isin(complete_data_ids)]\n",
    "\n",
    "print('Loaded ' + str(df_initial_full_filtered.shape[0]) + ' complete sets of initial blocks')\n",
    "# reduce to crucial information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_initial_full_filtered.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_initial_reduced_filtered = df_initial_full_filtered[[\n",
    "    'gameID','trialNum','phase','condition','eventType','targetName','repetition','targetID','blockNum', #trial identifiers\n",
    "    'nullScore','incrementalScore','normedIncrementalScore','rawScoreDiscrete','incrementalNormedScoreDiscretePrevious', #scoring\n",
    "    'score','currBonus', #bonusing\n",
    "    'timeAbsolute','timeRelative','timeBlockSelected','timeBlockPlaced','relativePlacementTime', #timing \n",
    "    'discreteWorld','vertices','blockKind','blockColorID','blockColor','blockCenterX', 'blockCenterY', #world reconstruction\n",
    "    'x_index','y_index','x_discrete','y_discrete','width_discrete','height_discrete'\n",
    "    ]]\n",
    "\n",
    "df_initial_reduced_filtered = df_initial_reduced_filtered.sort_values(by=['gameID', 'timeAbsolute'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_initial_reduced_filtered['rawScoreDiscrete']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = os.path.join(csv_dir,'block_silhouette_initial_{}.csv'.format(iterationName))\n",
    "df_initial_reduced_filtered.to_csv(out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settled Block Data\n",
    "Block data after coming to rest (after physics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = coll.find({\"$and\":[\n",
    "                        {'condition':{'$ne':'practice'}},\n",
    "                        {'eventType':'settled'},\n",
    "                        {'iterationName':iterationName}]\n",
    "                     })\n",
    "\n",
    "df_settled_full = pd.DataFrame(list(query))\n",
    "\n",
    "\n",
    "# filter dataframe for complete datasets\n",
    "df_settled_full_filtered = df_settled_full[df_settled_full.workerId.isin(complete_data_ids)]\n",
    "\n",
    "print('Loaded ' + str(df_settled_full_filtered.shape[0]) + ' complete sets of settled blocks')\n",
    "# reduce to crucial information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_settled_full_filtered.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_settled_reduced_filtered = df_settled_full_filtered[[\n",
    "    'gameID','trialNum','phase','condition','eventType','targetName','repetition','targetID', #trial identifiers\n",
    "    'nullScore','incrementalScore','normedIncrementalScore','rawScoreDiscrete','incrementalNormedScoreDiscrete','numBlocks','blockFell', #scoring\n",
    "    'score','currBonus', #bonusing\n",
    "    'timeAbsolute','timeRelative',#timing \n",
    "    'discreteWorld','allVertices','blockKind','blockColorID','blockColor','blockCenterX', 'blockCenterY',#world reconstruction\n",
    "    'x_index','y_index','x_discrete','y_discrete'\n",
    "    ]]\n",
    "\n",
    "df_settled_reduced_filtered = df_settled_reduced_filtered.sort_values(by=['gameID', 'timeAbsolute'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = os.path.join(csv_dir,'block_silhouette_settled_{}.csv'.format(iterationName))\n",
    "df_settled_reduced_filtered.to_csv(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = coll.find({\"$and\":[\n",
    "                        {'eventType':'survey_data'},\n",
    "                        {'iterationName':iterationName}]\n",
    "                     })\n",
    "df_survey = pd.DataFrame(list(query.sort('absoluteTime')))\n",
    "df_survey[['gameID','age','comments','difficulty','fun','strategies','inputDevice','sex','score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = os.path.join(csv_dir,'block_silhouette_survey_{}.csv'.format(iterationName))\n",
    "df_survey.to_csv(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
