{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import urllib, io\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "\n",
    "import pymongo as pm\n",
    "from collections import Counter\n",
    "import json\n",
    "import re\n",
    "import ast\n",
    "\n",
    "from PIL import Image, ImageOps, ImageDraw, ImageFont \n",
    "\n",
    "from io import BytesIO\n",
    "import base64\n",
    "\n",
    "import  matplotlib\n",
    "from matplotlib import pylab, mlab, pyplot\n",
    "%matplotlib inline\n",
    "from IPython.core.pylabtools import figsize, getfigs\n",
    "plt = pyplot\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_context('talk')\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## directory & file hierarchy\n",
    "proj_dir = os.path.abspath('..')\n",
    "datavol_dir = os.path.join(proj_dir,'data')\n",
    "analysis_dir = os.path.abspath(os.path.join(os.getcwd(),'..'))\n",
    "results_dir = os.path.join(proj_dir,'results')\n",
    "plot_dir = os.path.join(results_dir,'plots')\n",
    "csv_dir = os.path.join(results_dir,'csv')\n",
    "json_dir = os.path.join(results_dir,'json')\n",
    "exp_dir = os.path.abspath(os.path.join(proj_dir,'experiments'))\n",
    "png_dir = os.path.abspath(os.path.join(datavol_dir,'png'))\n",
    "jefan_dir = os.path.join(analysis_dir,'jefan')\n",
    "will_dir = os.path.join(analysis_dir,'will')\n",
    "\n",
    "## add helpers to python path\n",
    "if os.path.join(proj_dir,'stimuli') not in sys.path:\n",
    "    sys.path.append(os.path.join(proj_dir,'stimuli'))\n",
    "    \n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "    \n",
    "if not os.path.exists(plot_dir):\n",
    "    os.makedirs(plot_dir)   \n",
    "    \n",
    "if not os.path.exists(csv_dir):\n",
    "    os.makedirs(csv_dir)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set vars \n",
    "auth = pd.read_csv(os.path.join(analysis_dir,'auth.txt'), header = None) # this auth.txt file contains the password for the sketchloop user\n",
    "pswd = auth.values[0][0]\n",
    "user = 'sketchloop'\n",
    "host = 'cogtoolslab.org' ## cocolab ip address\n",
    "\n",
    "## have to fix this to be able to analyze from local\n",
    "import pymongo as pm\n",
    "conn = pm.MongoClient('mongodb://sketchloop:' + pswd + '@127.0.0.1')\n",
    "db = conn['block_construction']\n",
    "coll = db['silhouette']\n",
    "\n",
    "## which iteration name should we use?\n",
    "iterationName = 'pilot4'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure one to one gameID and workerId \n",
    "# Should only happen if a repeat worker gets through\n",
    "\n",
    "query = coll.find({\"$and\":[\n",
    "                        {'workerId':{'$exists':True}},\n",
    "                        {'condition':{'$ne':'practice'}},\n",
    "                        {'eventType':'trial_end'},\n",
    "                        {\"$or\":[{'iterationName':'pilot2'},\n",
    "                                {'iterationName':'pilot3'},\n",
    "                                {'iterationName':'pilot4'}]},\n",
    "                        {'trialNum':0}]\n",
    "                     })\n",
    "\n",
    "df_trial_end_full = pd.DataFrame(list(query.sort('timeAbsolute')))\n",
    "#df_trial_end_full[['workerId','gameID']]\n",
    "\n",
    "\n",
    "assert (np.mean(df_trial_end_full['workerId'].value_counts()) == np.mean(df_trial_end_full['gameID'].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get ids of people with trial 15 data\n",
    "query = coll.find({\"$and\":[\n",
    "                        {'condition':{'$ne':'practice'}},\n",
    "                        {'eventType':'trial_end'},\n",
    "                        {'iterationName': iterationName},\n",
    "                        {'trialNum':15}]\n",
    "                     })\n",
    "complete_data_df = pd.DataFrame(query)\n",
    "complete_data_ids = list(complete_data_df['workerId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data_df['workerId'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect data from db and filter with sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = coll.find({\"$and\":[\n",
    "                        {'condition':{'$ne':'practice'}},\n",
    "                        {'eventType':'trial_end'},\n",
    "                        {'iterationName':iterationName}]\n",
    "                     })\n",
    "\n",
    "df_trial_end_full = pd.DataFrame(list(query.sort('timeAbsolute')))\n",
    "\n",
    "\n",
    "\n",
    "# filter dataframe for complete datasets\n",
    "df_trial_end_full_filtered = df_trial_end_full[df_trial_end_full.workerId.isin(complete_data_ids)]\n",
    "\n",
    "\n",
    "# reduce to crucial information\n",
    "df_trial_end_reduced_filtered = df_trial_end_full_filtered[['gameID','trialNum','phase','condition',\n",
    "                                                            'eventType','score','normedScore','numBlocks',\n",
    "                                                            'timeAbsolute','timeRelative','buildTime',\n",
    "                                                            'currBonus','exploreResets','buildResets',\n",
    "                                                            'allVertices','nPracticeAttempts','exploreStartTime',\n",
    "                                                            'buildStartTime','buildFinishTime','targetName','numBlocksExplore']]\n",
    "\n",
    "df = df_trial_end_reduced_filtered.sort_values(by=['gameID', 'timeAbsolute'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrate reset data before sending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resets\n",
    "\n",
    "query = coll.find({\"$and\":[\n",
    "                        {'condition':{'$ne':'practice'}},\n",
    "                        {'eventType':'reset'},\n",
    "                        {'phase':'build'},\n",
    "                        {'iterationName':iterationName}]\n",
    "                     })\n",
    "df_resets_full = pd.DataFrame(list(query.sort('timeAbsolute')))\n",
    "df_resets_full_filtered = df_resets_full[df_resets_full.workerId.isin(complete_data_ids)]\n",
    "df_resets_reduced_filtered = df_resets_full_filtered[['gameID','trialNum','phase','condition','numBlocks']]\n",
    "pre_reset_blocks = df_resets_reduced_filtered.groupby(\n",
    "    ['gameID','trialNum','phase','condition'])['numBlocks'].apply(list).reset_index()\n",
    "\n",
    "# Merge pre-reset blocks with build data\n",
    "pre_reset_blocks = pre_reset_blocks.rename(columns = {'numBlocks':'preResetBuildBlocks'})\n",
    "\n",
    "pre_reset_blocks = pre_reset_blocks.fillna(value={'preResetBuildBlocks': 0})\n",
    "df = df.merge(pre_reset_blocks, on=['gameID', 'trialNum','phase','condition'], how='left')\n",
    "\n",
    "\n",
    "# Rename and add totals\n",
    "df = df.fillna(value={'preResetBuildBlocks': 0})\n",
    "df = df.rename(columns = {'numBlocks':'finalBuildBlocks'})\n",
    "df['totalBuildBlocks'] = df['finalBuildBlocks'] + df['preResetBuildBlocks'].apply(np.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save out to csv dir, where all the csv's go to live\n",
    "out_path = os.path.join(csv_dir,'block_silhouette_{}.csv'.format(iterationName))\n",
    "df_for_analysis.to_csv(out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settled Block Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading iteration: ' + iterationName)\n",
    "query = coll.find({\"$and\":[\n",
    "                        {'condition':{'$ne':'practice'}},\n",
    "                        {'eventType':'settled'},\n",
    "                        {'iterationName':iterationName}]\n",
    "                     })\n",
    "\n",
    "df_settled_full = pd.DataFrame(list(query))\n",
    "\n",
    "\n",
    "# filter dataframe for complete datasets\n",
    "df_settled_full_filtered = df_settled_full[df_settled_full.workerId.isin(complete_data_ids)]\n",
    "\n",
    "print('Loaded ' + str(df_settled_full_filtered.shape[0]) + ' complete sets of settled blocks')\n",
    "# reduce to crucial information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df_settled_reduced_filtered = df_settled_full_filtered[['gameID','trialNum','phase','condition',\n",
    "                                                            'eventType','numBlocks', 'timeAbsolute','timeRelative',\n",
    "                                                            'normedScore','currBonus','score','incrementalScore','normedIncrementalScore',\n",
    "                                                            'currBonus','allVertices','targetName','relativePlacementTime','iterationName',\n",
    "                                                            'blockKind'\n",
    "                                                           ]]\n",
    "\n",
    "df_settled_reduced_filtered = df_settled_reduced_filtered.sort_values(by=['gameID', 'timeAbsolute'])\n",
    "\n",
    "buildstart = df_for_analysis[['gameID','trialNum','buildStartTime','exploreStartTime']]\n",
    "\n",
    "# copy across time variables that were not saved in the correct place in pilot 3\n",
    "df_settled_reduced_filtered = df_settled_reduced_filtered.merge(buildstart, on=['gameID', 'trialNum'], how='left')\n",
    "df_settled_reduced_filtered['timePlaced'] = df_settled_reduced_filtered['timeAbsolute'] - df_settled_reduced_filtered['buildStartTime']\n",
    "df_settled_reduced_filtered.loc[(df_settled_reduced_filtered.timePlaced < 0),'timePlaced'] = df_settled_reduced_filtered[df_settled_reduced_filtered.timePlaced < 0]['timeAbsolute'] - df_settled_reduced_filtered[df_settled_reduced_filtered.timePlaced < 0]['exploreStartTime']\n",
    "\n",
    "# \n",
    "df_settled_reduced_filtered.loc[(df_settled_reduced_filtered.iterationName == 'pilot4'),'timePlaced'] = df_settled_reduced_filtered[(df_settled_reduced_filtered.iterationName == 'pilot4')]['relativePlacementTime'] \n",
    "df_settled_reduced_filtered.loc[(df_settled_reduced_filtered.timePlaced <= 0),'timePlaced'] = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save out to csv dir, where all the csv's go to live\n",
    "out_path = os.path.join(csv_dir,'block_silhouette_settled_{}.csv'.format(iterationName))\n",
    "df_settled_reduced_filtered.to_csv(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## which iteration name should we use?\n",
    "iterationName = 'pilot4'\n",
    "\n",
    "## load in dataframe\n",
    "data_path = os.path.join(csv_dir,'block_silhouette_settled_{}.csv'.format(iterationName))\n",
    "df = pd.read_csv(data_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure one to one gameID and workerId \n",
    "# Should only happen if a repeat worker gets through\n",
    "\n",
    "query = coll.find({\"$and\":[\n",
    "                        {'workerId':{'$exists':True}},\n",
    "                        {'condition':{'$ne':'practice'}},\n",
    "                        {'eventType':'explore_end'},\n",
    "                        {\"$or\":[{'iterationName':'pilot2'},\n",
    "                                {'iterationName':'pilot3'},\n",
    "                                {'iterationName':'pilot4'}]},\n",
    "                        {'trialNum':0}]\n",
    "                     })\n",
    "\n",
    "df_explore_end_full = pd.DataFrame(list(query.sort('timeAbsolute')))\n",
    "\n",
    "assert (np.mean(df_trial_end_full['workerId'].value_counts()) == np.mean(df_trial_end_full['gameID'].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get ids of people with trial 15 data\n",
    "query = coll.find({\"$and\":[\n",
    "                        {'condition':{'$ne':'practice'}},\n",
    "                        {'eventType':'explore_end'},\n",
    "                        {'iterationName': iterationName},\n",
    "                        {'trialNum':15}]\n",
    "                     })\n",
    "complete_data_df = pd.DataFrame(query)\n",
    "complete_data_ids = list(complete_data_df['workerId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = coll.find({\"$and\":[\n",
    "                        {'condition':{'$ne':'practice'}},\n",
    "                        {'eventType':'explore_end'},\n",
    "                        {'iterationName':iterationName}]\n",
    "                     })\n",
    "\n",
    "df_explore_end_full = pd.DataFrame(list(query.sort('timeAbsolute')))\n",
    "\n",
    "\n",
    "\n",
    "# filter dataframe for complete datasets\n",
    "df_explore_end_full_filtered = df_explore_end_full[df_explore_end_full.workerId.isin(complete_data_ids)]\n",
    "\n",
    "\n",
    "# reduce to crucial information\n",
    "df_explore_end_reduced_filtered = df_explore_end_full_filtered[['gameID','trialNum','phase','condition',\n",
    "                                                            'eventType','score','normedScore','numBlocks',\n",
    "                                                            'timeAbsolute','timeRelative',\n",
    "                                                            'currBonus','exploreResets',\n",
    "                                                            'allVertices','nPracticeAttempts','exploreStartTime',\n",
    "                                                            'targetName','numBlocksExplore']]\n",
    "\n",
    "df_explore = df_explore_end_reduced_filtered.sort_values(by=['gameID', 'timeAbsolute'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_explore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrate reset data before sending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resets\n",
    "\n",
    "query = coll.find({\"$and\":[\n",
    "                        {'condition':{'$ne':'practice'}},\n",
    "                        {'eventType':'reset'},\n",
    "                        {'phase':'explore'},\n",
    "                        {'iterationName':iterationName}]\n",
    "                     })\n",
    "df_resets_full = pd.DataFrame(list(query.sort('timeAbsolute')))\n",
    "df_resets_full_filtered = df_resets_full[df_resets_full.workerId.isin(complete_data_ids)]\n",
    "df_resets_reduced_filtered = df_resets_full_filtered[['gameID','trialNum','phase','condition','numBlocks']]\n",
    "pre_reset_blocks = df_resets_reduced_filtered.groupby(\n",
    "    ['gameID','trialNum','phase','condition'])['numBlocks'].apply(list).reset_index()\n",
    "\n",
    "# Merge pre-reset blocks with explore data\n",
    "pre_reset_blocks = pre_reset_blocks.rename(columns = {'numBlocks':'preResetExploreBlocks'})\n",
    "df_explore = df_explore.merge(pre_reset_blocks, on=['gameID', 'trialNum','phase','condition'], how='left')\n",
    "\n",
    "# Rename and add totals\n",
    "df_explore.loc[df_explore.preResetExploreBlocks.isnull(),'preResetExploreBlocks'] = df_explore.preResetExploreBlocks.loc[df_explore.preResetExploreBlocks.isnull()].apply(lambda x:[])\n",
    "df_explore = df_explore.rename(columns = {'numBlocksExplore':'finalExploreBlocks'})\n",
    "df_explore['totalExploreBlocks'] = df_explore['finalExploreBlocks'] + df_explore['preResetExploreBlocks'].apply(np.sum)\n",
    "\n",
    "#df_explore = df_explore.fillna(value={'totalExploreBlocks': 0 })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_explore['numAttempts'] = df_explore['preResetExploreBlocks'].apply(len) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save out to csv dir, where all the csv's go to live\n",
    "out_path = os.path.join(csv_dir,'block_silhouette_explore_{}.csv'.format(iterationName))\n",
    "df_explore.to_csv(out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### update numBlocksExplore in trial_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_explore' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-94d37535475e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_explore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_explore' is not defined"
     ]
    }
   ],
   "source": [
    "df_explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
